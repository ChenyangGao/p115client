#!/usr/bin/env python3
# encoding: utf-8

__author__ = "ChenyangGao <https://chenyanggao.github.io>"
__version__ = (0, 0, 9)
__all__ = [
    "upload_endpoint_url", "upload_url", "upload_token", "upload_token_open", 
    "upload_init", "upload_init_open", "upload_resume", "upload_resume_open", 
    "oss_upload_sign", "oss_upload_request", "oss_multipart_upload_url", 
    "oss_multipart_part_iter", "oss_multipart_upload_init", 
    "oss_multipart_upload_complete", "oss_multipart_upload_cancel", 
    "oss_multipart_upload_part", "oss_multipart_upload_part_iter", 
    "oss_upload_init", "oss_upload", "oss_multipart_upload", "upload", 
]

from asyncio import to_thread, Lock as AsyncLock
from base64 import b64encode
from collections import UserString
from collections.abc import (
    AsyncIterable, AsyncIterator, Buffer, Callable, 
    Coroutine, Iterable, Iterator, Mapping, Sequence, 
)
from datetime import datetime, timedelta
from email.utils import formatdate
from hashlib import sha1
from hmac import digest as hmac_digest
from inspect import isawaitable, iscoroutinefunction, signature
from itertools import count
from os import fsdecode, fstat, stat, PathLike
from threading import Lock
from typing import cast, overload, Any, Final, Literal
from urllib.parse import urlsplit, urlunsplit
from uuid import uuid4
from xml.etree.ElementTree import fromstring

from asynctools import ensure_async
from dicttools import iter_items, dict_update
from filewrap import (
    SupportsRead, buffer_length, 
    bio_chunk_iter, bio_chunk_async_iter, 
    bytes_iter_to_async_reader, bytes_iter_to_reader, 
    bytes_to_chunk_iter, bytes_to_chunk_async_iter, 
)
from hashtools import file_digest, file_digest_async
from http_request import complete_url, SupportsGeturl
from http_response import get_status_code, get_total_length, get_filename
from integer_tool import try_parse_int
from iterutils import (
    foreach, collect, peek_iter, run_gen_step, run_gen_step_iter, 
    wrap_iter, Yield, 
)
from orjson import loads
from p115cipher import ecdh_aes_decrypt, make_upload_payload
from p115pickcode import pickcode_to_id
from yarl import URL


_HEADERS: Final = {"user-agent": "", "accept-encoding": "identity"}
_UPLOAD_TOKEN: Final[dict[str, str]] = {}
_UPLOAD_TOKEN_LOCK: Final = Lock()
_UPLOAD_TOKEN_ASYNC_LOCK: Final = AsyncLock()


@overload
def _upload_token(
    refresh: bool = False, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> dict[str, str]:
    ...
@overload
def _upload_token(
    refresh: bool = False, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, dict[str, str]]:
    ...
def _upload_token(
    refresh: bool = False, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> dict[str, str] | Coroutine[Any, Any, dict[str, str]]:
    request_kwargs["parse"] = parse_json
    request_kwargs.pop("headers", None)
    def gen_step():
        if async_:
            lock: AsyncLock | Lock = _UPLOAD_TOKEN_ASYNC_LOCK
        else:
            lock = _UPLOAD_TOKEN_LOCK
        try:
            yield lock.acquire()
            expiration = _UPLOAD_TOKEN.get("Expiration") or ""
            if refresh:
                deadline = datetime.now() - timedelta(hours=7, minutes=10)
            else:
                deadline = datetime.now() - timedelta(hours=7, minutes=59)
            if expiration < deadline.strftime("%FT%XZ"):
                while True:
                    try:
                        resp = yield upload_token(async_=async_, **request_kwargs)
                    except Exception:
                        continue
                    if resp.get("StatusCode") == "200":
                        break
                _UPLOAD_TOKEN.update(resp)
        finally:
            lock.release()
        return _UPLOAD_TOKEN
    return run_gen_step(gen_step, async_)


def to_base64(s: Buffer | str | UserString, /) -> str:
    if isinstance(s, (str, UserString)):
        s = s.encode("utf-8")
    return str(b64encode(s), "ascii")


def parse_json(_, content: Buffer, /):
    return loads(memoryview(content))


def parse_upload_id(_, content: bytes, /) -> str:
    return getattr(fromstring(content).find("UploadId"), "text")


def get_request(
    request_kwargs: dict, 
    async_: Literal[False, True] = False, 
):
    request = request_kwargs.pop("request", None)
    request_kwargs.setdefault("parse", parse_json)
    if request is None:
        from httpcore_request import request
        request_kwargs["async_"] = async_
    else:
        def has_keyword_async(request: Callable, /) -> bool:
            try:
                sig = signature(request)
            except (ValueError, TypeError):
                return False
            params = sig.parameters
            param = params.get("async_")
            return bool(param and param.kind in (param.POSITIONAL_OR_KEYWORD, param.KEYWORD_ONLY))
        if iscoroutinefunction(request):
            async_ = True
        if async_ is not None and has_keyword_async(request):
            request_kwargs["async_"] = async_
    return request


def determine_partsize(
    size: int, 
    max_part_count: int = 10 ** 4, 
) -> int:
    """ç¡®å®šåˆ†ç‰‡ä¸Šä¼ ï¼ˆmultipart uploadï¼‰æ—¶çš„åˆ†ç‰‡å¤§å°

    :param size: æ•°æ®å¤§å°
    :param min_part_size:  ç”¨æˆ·æœŸæœ›çš„åˆ†ç‰‡å¤§å°
    :param max_part_count: æœ€å¤§çš„åˆ†ç‰‡ä¸ªæ•°

    :return: åˆ†ç‰‡å¤§å°
    """
    min_part_size = 1024 * 1024 * 10
    if size <= min_part_size:
        return min_part_size
    n = -(-size // max_part_count)
    partsize = min_part_size
    while partsize < n:
        partsize <<= 1
    return partsize


def upload_endpoint_url(
    object: str, 
    bucket: str = "fhnfile", 
    endpoint: str = "http://oss-cn-shenzhen.aliyuncs.com", 
) -> str:
    """æ„é€ ä¸Šä¼ æ—¶çš„ url

    :param bucket: å­˜å‚¨æ¡¶
    :param object: å­˜å‚¨å¯¹è±¡ id
    :param endpoint: ä¸Šä¼ ç›®çš„ç½‘å€

    :return: ä¸Šä¼ æ—¶æ‰€ç”¨çš„ url
    """
    urlp = urlsplit(endpoint)
    return f"{urlp.scheme}://{bucket}.{urlp.netloc}/{object}"


@overload
def upload_url(
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> dict:
    ...
@overload
def upload_url(
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, dict]:
    ...
def upload_url(
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> dict | Coroutine[Any, Any, dict]:
    """è·å–ä¸Šä¼ ç›®çš„ç½‘å€å’Œè·å– ``token`` çš„ç½‘å€

    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: ç½‘å€çš„å­—å…¸ï¼Œ"endpoint" æ˜¯ä¸Šä¼ ç›®çš„ç½‘å€ï¼Œ"gettokenurl" æ˜¯è·å– ``token`` çš„ç½‘å€
    """
    api = "https://uplb.115.com/3.0/getuploadinfo.php"
    return get_request(request_kwargs, async_=async_)(url=api, **request_kwargs)


@overload
def upload_token(
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> dict:
    ...
@overload
def upload_token(
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, dict]:
    ...
def upload_token(
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> dict | Coroutine[Any, Any, dict]:
    """è·å–ä¸Šä¼ ç”¨åˆ°çš„ä»¤ç‰Œä¿¡æ¯ï¼ˆå­—å…¸ï¼‰

    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: ä»¤ç‰Œä¿¡æ¯ï¼ˆå­—å…¸ï¼‰
    """
    api = "https://uplb.115.com/3.0/gettoken.php"
    return get_request(request_kwargs, async_=async_)(url=api, **request_kwargs)


@overload
def upload_token_open(
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> dict:
    ...
@overload
def upload_token_open(
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, dict]:
    ...
def upload_token_open(
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> dict | Coroutine[Any, Any, dict]:
    """è·å–ä¸Šä¼ ç”¨åˆ°çš„ä»¤ç‰Œä¿¡æ¯ï¼ˆå­—å…¸ï¼‰

    .. caution::
        éœ€è¦æºå¸¦ "authorization" è¯·æ±‚å¤´

    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: ä»¤ç‰Œä¿¡æ¯ï¼ˆå­—å…¸ï¼‰
    """
    api = "https://proapi.115.com/open/upload/get_token"
    return get_request(request_kwargs, async_=async_)(url=api, **request_kwargs)


@overload
def upload_init(
    payload: dict, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> dict:
    ...
@overload
def upload_init(
    payload: dict, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, dict]:
    ...
def upload_init(
    payload: dict, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> dict | Coroutine[Any, Any, dict]:
    """ä¸Šä¼ åˆå§‹åŒ–

    :param payload: è¯·æ±‚å‚æ•°

        - userid: int | str     ğŸ’¡ ç”¨æˆ· id
        - userkey: str          ğŸ’¡ ç”¨æˆ·çš„ key
        - fileid: str           ğŸ’¡ æ–‡ä»¶çš„ sha1
        - filename: str         ğŸ’¡ æ–‡ä»¶å
        - filesize: int         ğŸ’¡ æ–‡ä»¶å¤§å°
        - target: str = "U_1_0" ğŸ’¡ ä¿å­˜ç›®æ ‡ï¼Œæ ¼å¼ä¸º f"U_{aid}_{pid}"
        - sign_key: str = ""    ğŸ’¡ 2 æ¬¡éªŒè¯çš„ key
        - sign_val: str = ""    ğŸ’¡ 2 æ¬¡éªŒè¯çš„å€¼
        - topupload: int | str = "true" ğŸ’¡ ä¸Šä¼ è°ƒåº¦æ–‡ä»¶ç±»å‹è°ƒåº¦æ ‡è®°

    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: æ¥å£å“åº”
    """
    api = "https://uplb.115.com/4.0/initupload.php"
    data = {
        "appid": 0, 
        "target": "U_1_0", 
        "sign_key": "", 
        "sign_val": "", 
        "topupload": "true", 
        **payload, 
        "appversion": "99.99.99.99", 
    }
    request_kwargs["method"] = "POST"
    request_kwargs["headers"] = dict_update(
        dict(request_kwargs.get("headers") or ()), 
        {
            "content-type": "application/x-www-form-urlencoded", 
            "user-agent": "Mozilla/5.0 115disk/99.99.99.99 115Browser/99.99.99.99 115wangpan_android/99.99.99.99", 
        }, 
    )
    request_kwargs.update(make_upload_payload(data))
    def parse_upload_init_response(_, content: bytes, /) -> dict:
        data = ecdh_aes_decrypt(content, decompress=True)
        return parse_json(None, data)
    request_kwargs.setdefault("parse", parse_upload_init_response)
    return get_request(request_kwargs, async_=async_)(url=api, **request_kwargs)


@overload
def upload_init_open(
    payload: dict, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> dict:
    ...
@overload
def upload_init_open(
    payload: dict, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, dict]:
    ...
def upload_init_open(
    payload: dict, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> dict | Coroutine[Any, Any, dict]:
    """ä¸Šä¼ åˆå§‹åŒ–ï¼ˆå¼€æ”¾æ¥å£ï¼‰

    .. caution::
        éœ€è¦æºå¸¦ "authorization" è¯·æ±‚å¤´

    :param payload: è¯·æ±‚å‚æ•°

        - fileid: str              ğŸ’¡ æ–‡ä»¶çš„ sha1
        - file_name: str           ğŸ’¡ æ–‡ä»¶å
        - file_size: int           ğŸ’¡ æ–‡ä»¶å¤§å°
        - target: str = "U_1_0"    ğŸ’¡ ä¿å­˜ç›®æ ‡ï¼Œæ ¼å¼ä¸º f"U_{aid}_{pid}"
        - sign_key: str = ""       ğŸ’¡ 2 æ¬¡éªŒè¯çš„ key
        - sign_val: str = ""       ğŸ’¡ 2 æ¬¡éªŒè¯çš„å€¼
        - topupload: int | str = 1 ğŸ’¡ ä¸Šä¼ è°ƒåº¦æ–‡ä»¶ç±»å‹è°ƒåº¦æ ‡è®°

            -  0: å•æ–‡ä»¶ä¸Šä¼ ä»»åŠ¡æ ‡è¯† 1 æ¡å•ç‹¬çš„æ–‡ä»¶ä¸Šä¼ è®°å½•
            -  1: ç›®å½•ä»»åŠ¡è°ƒåº¦çš„ç¬¬ 1 ä¸ªå­æ–‡ä»¶ä¸Šä¼ è¯·æ±‚æ ‡è¯† 1 æ¬¡ç›®å½•ä¸Šä¼ è®°å½•
            -  2: ç›®å½•ä»»åŠ¡è°ƒåº¦çš„å…¶ä½™åç»­å­æ–‡ä»¶ä¸ä½œè®°ä½œå•ç‹¬ä¸Šä¼ çš„ä¸Šä¼ è®°å½• 
            - -1: æ²¡æœ‰è¯¥å‚æ•°

    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: æ¥å£å“åº”
    """
    api = "https://proapi.115.com/open/upload/init"
    request_kwargs.update(
        method="POST", 
        data={"target": "U_1_0", "topupload": 1, **payload}, 
    )
    return get_request(request_kwargs, async_=async_)(url=api, **request_kwargs)


@overload
def upload_resume(
    payload: dict, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> dict:
    ...
@overload
def upload_resume(
    payload: dict, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, dict]:
    ...
def upload_resume(
    payload: dict, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> dict | Coroutine[Any, Any, dict]:
    """æ¢å¤ä¸Šä¼ ï¼ˆä¸»è¦ç”¨äºåˆ†å—ä¸Šä¼ ï¼‰

    .. note::
        ``payload`` ä¸­åŒ…å« "callback" æˆ– "callback_var" å­—æ®µï¼Œåˆ™å¯ä»¥è¢«è‡ªåŠ¨å¤„ç†ï¼ˆå³ä½¿ç›¸å…³å­—æ®µç¼ºå¤±ï¼‰

        å³ä½¿ä½ ä»…ä¿å­˜äº† ``upload_id`` å’Œ ``callback``ï¼Œä¹Ÿèƒ½è®©ä½ æ–­ç‚¹ç»­ä¼ 

    :param payload: éœ€è¦æ¥å—ä¸‹é¢è¿™äº›å‚æ•°

        - pickcode: str ğŸ’¡ æå–ç 
        - userid: int   ğŸ’¡ ç”¨æˆ· id
        - target: str   ğŸ’¡ ä¸Šä¼ ç›®æ ‡ï¼Œé»˜è®¤ä¸º "U_1_0"ï¼Œæ ¼å¼ä¸º f"U_{aid}_{pid}"
        - fileid: str   ğŸ’¡ æ–‡ä»¶çš„ sha1 å€¼ï¼ˆâš ï¸ å¯ä»¥æ˜¯ä»»æ„å€¼ï¼‰
        - filesize: int ğŸ’¡ æ–‡ä»¶å¤§å°ï¼Œå•ä½æ˜¯å­—èŠ‚ï¼ˆâš ï¸ å¯ä»¥æ˜¯ä»»æ„å€¼ï¼‰

    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: æ¥å£å“åº”
    """
    api = "https://uplb.115.com/3.0/resumeupload.php"
    data: dict = dict(payload)
    if "pickcode" not in data:
        if "callback_var" in data:
            callback_var = loads(data["callback_var"])
        elif "callback" in data:
            callback_var = loads(data["callback"]["callback_var"])
        else:
            raise ValueError(f"invalid payload: {payload!r}")
        data.update(
            pickcode=callback_var["x:pick_code"], 
            target=callback_var["x:target"], 
            userid=callback_var["x:user_id"]
        )
    data.setdefault("fileid", "0" * 40)
    data.setdefault("filesize", 1)
    data.setdefault("target", "U_1_0")
    request_kwargs.update(method="POST", data=data)
    return get_request(request_kwargs, async_=async_)(url=api, **request_kwargs)


@overload
def upload_resume_open(
    payload: dict | str, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> dict:
    ...
@overload
def upload_resume_open(
    payload: dict | str, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, dict]:
    ...
def upload_resume_open(
    payload: dict | str, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> dict | Coroutine[Any, Any, dict]:
    """æ¢å¤ä¸Šä¼ ï¼ˆä¸»è¦ç”¨äºåˆ†å—ä¸Šä¼ ï¼‰

    .. caution::
        éœ€è¦æºå¸¦ "authorization" è¯·æ±‚å¤´

    .. note::
        ``payload`` ä¸­åŒ…å« "callback" æˆ– "callback_var" å­—æ®µï¼Œåˆ™å¯ä»¥è¢«è‡ªåŠ¨å¤„ç†ï¼ˆå³ä½¿ç›¸å…³å­—æ®µç¼ºå¤±ï¼‰

        å³ä½¿ä½ ä»…ä¿å­˜äº† ``upload_id`` å’Œ ``callback``ï¼Œä¹Ÿèƒ½è®©ä½ æ–­ç‚¹ç»­ä¼ 

    :param payload: éœ€è¦æ¥å—ä¸‹é¢è¿™äº›å‚æ•°

        - pick_code: str ğŸ’¡ æå–ç 
        - target: str    ğŸ’¡ ä¸Šä¼ ç›®æ ‡ï¼Œé»˜è®¤ä¸º "U_1_0"ï¼Œæ ¼å¼ä¸º f"U_{aid}_{pid}"
        - fileid: str    ğŸ’¡ æ–‡ä»¶çš„ sha1 å€¼ï¼ˆâš ï¸ å¯ä»¥æ˜¯ä»»æ„å€¼ï¼‰
        - file_size: int ğŸ’¡ æ–‡ä»¶å¤§å°ï¼Œå•ä½æ˜¯å­—èŠ‚ï¼ˆâš ï¸ å¯ä»¥æ˜¯ä»»æ„å€¼ï¼‰

    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: æ¥å£å“åº”
    """
    api = "https://proapi.115.com/open/upload/resume"
    if isinstance(payload, str):
        data: dict = {"pick_code": payload}
    else:
        data = dict(payload)
        if "pick_code" not in data:
            if "callback_var" in data:
                callback_var = loads(data["callback_var"])
            elif "callback" in data:
                callback_var = loads(data["callback"]["callback_var"])
            else:
                raise ValueError(f"invalid payload: {payload!r}")
            data.update(
                pick_code=callback_var["x:pick_code"], 
                target=callback_var["x:target"], 
            )
    data.setdefault("fileid", "0" * 40)
    data.setdefault("file_size", 1)
    data.setdefault("target", "U_1_0")
    request_kwargs.update(method="POST", data=data)
    return get_request(request_kwargs, async_=async_)(url=api, **request_kwargs)


@overload
def oss_upload_sign(
    url: str, 
    method: str = "POST", 
    headers: None | Mapping[str, str] | Iterable[tuple[str, str]] = None, 
    token: None | dict = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> dict:
    ...
@overload
def oss_upload_sign(
    url: str, 
    method: str = "POST", 
    headers: None | Mapping[str, str] | Iterable[tuple[str, str]] = None, 
    token: None | dict = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> dict:
    ...
def oss_upload_sign(
    url: str, 
    method: str = "POST", 
    headers: None | Mapping[str, str] | Iterable[tuple[str, str]] = None, 
    token: None | dict = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> dict:
    """è®¡ç®—ç„¶åè¿”å›å¸¦è®¤è¯ä¿¡æ¯çš„è¯·æ±‚å¤´

    :param token: ä¸Šä¼ ç”¨åˆ°çš„ä»¤ç‰Œä¿¡æ¯ï¼ˆå­—å…¸ï¼‰
    :param method: HTTP è¯·æ±‚æ–¹æ³•
    :param url: HTTP è¯·æ±‚é“¾æ¥
    :param headers: é»˜è®¤çš„è¯·æ±‚å¤´
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: å¸¦è®¤è¯ä¿¡æ¯çš„è¯·æ±‚å¤´
    """
    # subresource_keys = (
    #     "accessPoint", "accessPointPolicy", "acl", "append", "asyncFetch", "bucketArchiveDirectRead", 
    #     "bucketInfo", "callback", "callback-var", "cname", "comp", "continuation-token", "cors", 
    #     "delete", "encryption", "endTime", "group", "httpsConfig", "inventory", "inventoryId", 
    #     "lifecycle", "link", "live", "location", "logging", "metaQuery", "objectInfo", "objectMeta", 
    #     "partNumber", "policy", "position", "publicAccessBlock", "qos", "qosInfo", "qosRequester", 
    #     "redundancyTransition", "referer", "regionList", "replication", "replicationLocation", 
    #     "replicationProgress", "requestPayment", "requesterQosInfo", "resourceGroup", "resourcePool", 
    #     "resourcePoolBuckets", "resourcePoolInfo", "response-cache-control", "response-content-disposition", 
    #     "response-content-encoding", "response-content-language", "response-content-type", "response-expires", 
    #     "restore", "security-token", "sequential", "startTime", "stat", "status", "style", "styleName", 
    #     "symlink", "tagging", "transferAcceleration", "uploadId", "uploads", "versionId", "versioning", 
    #     "versions", "vod", "website", "worm", "wormExtend", "wormId", "x-oss-ac-forward-allow", 
    #     "x-oss-ac-source-ip", "x-oss-ac-subnet-mask", "x-oss-ac-vpc-id", "x-oss-access-point-name", 
    #     "x-oss-async-process", "x-oss-process", "x-oss-redundancy-transition-taskid", "x-oss-request-payer", 
    #     "x-oss-target-redundancy-type", "x-oss-traffic-limit", "x-oss-write-get-object-response", 
    # )
    def gen_step():
        nonlocal headers, token
        if not token:
            token = yield _upload_token(async_=async_, **request_kwargs)
        urlp = urlsplit(url)
        bucket = cast(str, urlp.hostname).partition(".")[0]
        headers = {k.lower(): v for k, v in iter_items(headers or ())}
        headers["x-oss-security-token"] = token["SecurityToken"]
        date = headers["date"] = headers.get("x-oss-date") or headers.get("date") or formatdate(usegmt=True)
        signature = to_base64(hmac_digest(
            bytes(token["AccessKeySecret"], "utf-8"), 
            f"""\
{method.upper()}
{headers.setdefault("content-md5", "")}
{headers.setdefault("content-type", "")}
{date}
{"\n".join(map(
    "%s:%s".__mod__, 
    sorted(e for e in headers.items() if e[0].startswith("x-oss-"))
))}
/{bucket}{urlunsplit(urlp._replace(scheme="", netloc=""))}""".encode("utf-8"), 
            "sha1", 
        ))
        headers["authorization"] = "OSS {0}:{1}".format(token["AccessKeyId"], signature)
        return headers
    return run_gen_step(gen_step, async_)


def oss_upload_request(
    url: str, 
    method: str = "POST", 
    params: None | str | Mapping | Sequence[tuple[Any, Any]] = None, 
    token: None | dict = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
):
    """è¯·æ±‚é˜¿é‡Œäº‘ OSS çš„å…¬ç”¨å‡½æ•°
    """
    assert url
    if not url.strip("1234567890abcdef"):
        url = "http://fhnfile.oss-cn-shenzhen.aliyuncs.com/" + url
    url = complete_url(url, params=params)
    def gen_step():
        nonlocal token
        if not token:
            token = yield _upload_token(async_=async_, **request_kwargs)
        request_kwargs["headers"] = oss_upload_sign(
            url, 
            method=method, 
            headers=request_kwargs.get("headers"), 
            token=token, 
        )
        return get_request(request_kwargs, async_=async_)(
            url=url, 
            method=method, 
            **request_kwargs, 
        )
    return run_gen_step(gen_step, async_)


@overload
def oss_multipart_upload_url(
    url: str, 
    upload_id: int | str, 
    part_number: int = 1, 
    token: None | dict = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> tuple[str, dict]:
    ...
@overload
def oss_multipart_upload_url(
    url: str, 
    upload_id: int | str, 
    part_number: int = 1, 
    token: None | dict = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, tuple[str, dict]]:
    ...
def oss_multipart_upload_url(
    url: str, 
    upload_id: int | str, 
    part_number: int = 1, 
    token: None | dict = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> tuple[str, dict] | Coroutine[Any, Any, tuple[str, dict]]:
    """è·å–åˆ†å—ä¸Šä¼ çš„é“¾æ¥å’Œè¯·æ±‚å¤´

    :param url: HTTP è¯·æ±‚é“¾æ¥
    :param upload_id: ä¸Šä¼ ä»»åŠ¡çš„ id
    :param part_number: åˆ†å—ç¼–å·ï¼ˆä» 1 å¼€å§‹ï¼‰
    :param token: ä¸Šä¼ ç”¨åˆ°çš„ä»¤ç‰Œä¿¡æ¯ï¼ˆå­—å…¸ï¼‰
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°   

    :return: ä¸Šä¼ é“¾æ¥ å’Œ è¯·æ±‚å¤´ çš„ 2 å…ƒç»„
    """
    assert url
    if not url.strip("1234567890abcdef"):
        url = "http://fhnfile.oss-cn-shenzhen.aliyuncs.com/" + url
    url = complete_url(url, params={"partNumber": part_number, "uploadId": upload_id})
    def gen_step():
        nonlocal token
        if not token:
            token = yield _upload_token(refresh=True, async_=async_, **request_kwargs)
        headers = yield oss_upload_sign(
            url=url, 
            method="PUT", 
            token=token, 
            async_=async_, 
            **request_kwargs, 
        )
        return url, headers
    return run_gen_step(gen_step, async_)


@overload
def oss_multipart_part_iter(
    url: str, 
    upload_id: str, 
    token: None | dict = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def oss_multipart_part_iter(
    url: str, 
    upload_id: str, 
    token: None | dict = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def oss_multipart_part_iter(
    url: str, 
    upload_id: str, 
    token: None | dict = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """ç½—åˆ—æŸä¸ªåˆ†å—ä¸Šä¼ ä»»åŠ¡ï¼Œå·²ç»ä¸Šä¼ çš„åˆ†å—

    :param url: HTTP è¯·æ±‚é“¾æ¥
    :param upload_id: ä¸Šä¼ ä»»åŠ¡çš„ id
    :param token: ä¸Šä¼ ç”¨åˆ°çš„ä»¤ç‰Œä¿¡æ¯ï¼ˆå­—å…¸ï¼‰
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°    

    :return: ä¸Šä¼ å®Œæˆåˆ†å—ä¿¡æ¯çš„è¿­ä»£å™¨
    """
    request_kwargs.update(
        method="GET", 
        params={"uploadId": upload_id}, 
        parse=False, 
    )
    def gen_step():
        params = request_kwargs["params"]
        while True:
            content = yield oss_upload_request(
                url=url, 
                token=token, 
                async_=async_, 
                **request_kwargs, 
            )
            etree = fromstring(content)
            for el in etree.iterfind("Part"):
                yield Yield({sel.tag: try_parse_int(sel.text) for sel in el})
            if getattr(etree.find("IsTruncated"), "text") == "false":
                break
            params["part-number-marker"] = getattr(etree.find("NextPartNumberMarker"), "text")
    return run_gen_step_iter(gen_step, async_)


@overload
def oss_multipart_upload_init(
    url: str, 
    token: None | dict = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> str:
    ...
@overload
def oss_multipart_upload_init(
    url: str, 
    token: None | dict = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, str]:
    ...
def oss_multipart_upload_init(
    url: str, 
    token: None | dict = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> str | Coroutine[Any, Any, str]:
    """åˆå§‹åŒ–ï¼Œä»¥è·å–åˆ†å—ä¸Šä¼ ä»»åŠ¡çš„ id

    :param url: HTTP è¯·æ±‚é“¾æ¥
    :param token: ä¸Šä¼ ç”¨åˆ°çš„ä»¤ç‰Œä¿¡æ¯ï¼ˆå­—å…¸ï¼‰
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: åˆ†å—ä¸Šä¼ ä»»åŠ¡çš„ id
    """
    request_kwargs.update(
        method="POST", 
        params={"sequential": "1", "uploads": "1"}, 
    )
    request_kwargs.setdefault("parse", parse_upload_id)
    return oss_upload_request(
        url=url, 
        token=token, 
        async_=async_, 
        **request_kwargs, 
    )


@overload
def oss_multipart_upload_complete(
    url: str, 
    callback: dict, 
    upload_id: str, 
    parts: None | list[dict] = None, 
    token: None | dict = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> dict:
    ...
@overload
def oss_multipart_upload_complete(
    url: str, 
    callback: dict, 
    upload_id: str, 
    parts: None | list[dict] = None, 
    token: None | dict = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, dict]:
    ...
def oss_multipart_upload_complete(
    url: str, 
    callback: dict, 
    upload_id: str, 
    parts: None | list[dict] = None, 
    token: None | dict = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> dict | Coroutine[Any, Any, dict]:
    """å®Œæˆåˆ†å—ä¸Šä¼ ä»»åŠ¡

    :param url: HTTP è¯·æ±‚é“¾æ¥
    :param callback: å›è°ƒæ•°æ®
    :param upload_id: ä¸Šä¼ ä»»åŠ¡ id
    :pamra parts: å·²å®Œæˆçš„åˆ†å—ä¿¡æ¯åˆ—è¡¨
    :param token: ä¸Šä¼ ç”¨åˆ°çš„ä»¤ç‰Œä¿¡æ¯ï¼ˆå­—å…¸ï¼‰
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: æ¥å£å“åº”
    """
    def gen_step():
        nonlocal parts
        if parts is None:
            parts = yield collect(oss_multipart_part_iter(
                url=url, 
                upload_id=upload_id, 
                token=token, 
                async_=async_, 
                **request_kwargs, 
            ))
        request_kwargs.update(
            method="POST", 
            params={"uploadId": upload_id}, 
            data=b"".join((
                b"<CompleteMultipartUpload>", 
                *map(
                    b"<Part><PartNumber>%d</PartNumber><ETag>%s</ETag></Part>".__mod__, 
                    ((part["PartNumber"], bytes(part["ETag"], "ascii")) for part in parts), 
                ), 
                b"</CompleteMultipartUpload>", 
            )), 
            headers=dict_update(
                dict(request_kwargs.get("headers") or ()), 
                {
                    "x-oss-callback": to_base64(callback["callback"]), 
                    "x-oss-callback-var": to_base64(callback["callback_var"]), 
                    "content-type": "text/xml", 
                }, 
            ), 
        )
        return oss_upload_request(
            url=url, 
            token=token, 
            async_=async_, 
            **request_kwargs, 
        )
    return run_gen_step(gen_step, async_)


@overload
def oss_multipart_upload_cancel(
    url: str, 
    upload_id: str, 
    token: None | dict = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> bool:
    ...
@overload
def oss_multipart_upload_cancel(
    url: str, 
    upload_id: str, 
    token: None | dict = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, bool]:
    ...
def oss_multipart_upload_cancel(
    url: str, 
    upload_id: str, 
    token: None | dict = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> bool | Coroutine[Any, Any, bool]:
    """å–æ¶ˆåˆ†å—ä¸Šä¼ ä»»åŠ¡

    :param url: HTTP è¯·æ±‚é“¾æ¥
    :param upload_id: ä¸Šä¼ ä»»åŠ¡ id
    :param token: ä¸Šä¼ ç”¨åˆ°çš„ä»¤ç‰Œä¿¡æ¯ï¼ˆå­—å…¸ï¼‰
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: æ˜¯å¦æˆåŠŸ
    """
    request_kwargs.update(
        method="DELETE", 
        params={"uploadId": upload_id}, 
        raise_for_status=False, 
    )
    request_kwargs.setdefault(
        "parse", 
        lambda resp: (code := get_status_code(resp)) == 404 or 200 <= code < 300, 
    )
    return oss_upload_request(
        url=url, 
        token=token, 
        async_=async_, 
        **request_kwargs, 
    )


@overload
def oss_multipart_upload_part(
    url: str, 
    file: Buffer | SupportsRead | Iterable[Buffer], 
    upload_id: str, 
    part_number: int, 
    token: None | dict = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> dict:
    ...
@overload
def oss_multipart_upload_part(
    url: str, 
    file: Buffer | SupportsRead | Iterable[Buffer] | AsyncIterable[Buffer], 
    upload_id: str, 
    part_number: int, 
    token: None | dict = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, dict]:
    ...
def oss_multipart_upload_part(
    url: str, 
    file: Buffer | SupportsRead | Iterable[Buffer] | AsyncIterable[Buffer], 
    upload_id: str, 
    part_number: int, 
    token: None | dict = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> dict | Coroutine[Any, Any, dict]:
    """ä¸Šä¼ ä¸€ä¸ªåˆ†å—

    :param url: HTTP è¯·æ±‚é“¾æ¥
    :param file: æ–‡ä»¶æ•°æ®
    :param upload_id: ä¸Šä¼ ä»»åŠ¡ id
    :param part_number: åˆ†å—ç¼–å·ï¼ˆä» 1 å¼€å§‹ï¼‰
    :param token: ä¸Šä¼ ç”¨åˆ°çš„ä»¤ç‰Œä¿¡æ¯ï¼ˆå­—å…¸ï¼‰
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: ä¸Šä¼ å®Œæˆçš„åˆ†å—çš„ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«å¦‚ä¸‹å­—æ®µï¼š

        .. code:: python

            {
                "PartNumber": int,    # åˆ†å—åºå·ï¼Œä» 1 å¼€å§‹è®¡æ•°
                "LastModified": str,  # æœ€è¿‘æ›´æ–°æ—¶é—´
                "ETag": str,          # ETag å€¼ï¼Œåˆ¤æ–­èµ„æºæ˜¯å¦å‘ç”Ÿå˜åŒ–
                "HashCrc64ecma": int, # æ ¡éªŒç 
                "Size": int,          # åˆ†å—å¤§å°
            }
    """
    count_in_bytes = 0
    if isinstance(file, Buffer):
        count_in_bytes = buffer_length(file)
    else:
        if isinstance(file, SupportsRead):
            if async_:
                file = bio_chunk_async_iter(file)
            else:
                file = bio_chunk_iter(cast(SupportsRead, file))
        def acc(chunk: Buffer, /):
            nonlocal count_in_bytes
            count_in_bytes += buffer_length(chunk)
        file = wrap_iter(file, callnext=acc)
    def parse_upload_part(resp, /) -> dict:
        headers = resp.headers
        return {
            "PartNumber": part_number, 
            "LastModified": datetime.strptime(headers["date"], "%a, %d %b %Y %H:%M:%S GMT").strftime("%FT%X.%f")[:-3] + "Z", 
            "ETag": headers["ETag"], 
            "HashCrc64ecma": int(headers["x-oss-hash-crc64ecma"]), 
            "Size": count_in_bytes, 
        }
    request_kwargs.update(
        method="PUT", 
        params={"partNumber": part_number, "uploadId": upload_id}, 
        data=file, 
    )
    request_kwargs.setdefault("parse", parse_upload_part)
    return oss_upload_request(
        url=url, 
        token=token, 
        async_=async_, 
        **request_kwargs, 
    )


@overload
def oss_multipart_upload_part_iter(
    url: str, 
    file: Buffer | SupportsRead | Iterable[Buffer], 
    upload_id: str, 
    partsize: int, 
    part_number_start: int = 1, 
    token: None | dict = None, 
    reporthook: None | Callable[[int], Any] = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def oss_multipart_upload_part_iter(
    url: str, 
    file: Buffer | SupportsRead | Iterable[Buffer] | AsyncIterable[Buffer], 
    upload_id: str, 
    partsize: int, 
    part_number_start: int = 1, 
    token: None | dict = None, 
    reporthook: None | Callable[[int], Any] = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def oss_multipart_upload_part_iter(
    url: str, 
    file: Buffer | SupportsRead | Iterable[Buffer] | AsyncIterable[Buffer], 
    upload_id: str, 
    partsize: int, 
    part_number_start: int = 1, 
    token: None | dict = None, 
    reporthook: None | Callable[[int], Any] = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """è¿­ä»£å™¨ï¼Œè¿­ä»£ä¸€æ¬¡ä¼šä¸Šä¼ ä¸€ä¸ªåˆ†å—

    .. attention::
        å¦‚æœéœ€è¦è·³è¿‡ä¸€å®šçš„æ•°æ®ï¼Œè¯·æå‰å¤„ç†å¥½ï¼Œè¿™ä¸ªä¸ç®¡æ•°æ®æ˜¯å¦è¢«é‡å¤ä¸Šä¼ 

    :param url: HTTP è¯·æ±‚é“¾æ¥
    :param file: æ–‡ä»¶æ•°æ®
    :param upload_id: ä¸Šä¼ ä»»åŠ¡ id
    :param partsize: åˆ†å—å¤§å°
    :param part_number_start: å¼€å§‹çš„åˆ†å—ç¼–å·ï¼ˆä» 1 å¼€å§‹ï¼‰
    :param token: ä¸Šä¼ ç”¨åˆ°çš„ä»¤ç‰Œä¿¡æ¯ï¼ˆå­—å…¸ï¼‰
    :param reporthook: å›è°ƒå‡½æ•°ï¼Œå¯ä»¥ç”¨æ¥ç»Ÿè®¡å·²ä¸Šä¼ çš„æ•°æ®é‡æˆ–è€…å±•ç¤ºè¿›åº¦æ¡
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: ä¸Šä¼ å®Œæˆçš„åˆ†å—ä¿¡æ¯çš„è¿­ä»£å™¨
    """
    if isinstance(file, (Buffer, SupportsRead)):
        pass
    elif async_:
        file = bytes_iter_to_async_reader(file)
    else:
        file = bytes_iter_to_reader(cast(Iterable, file))
    def gen_step():
        chunk: Buffer | Iterator[Buffer] | AsyncIterator[Buffer]
        end_with_reporthook = reporthook is not None and isinstance(file, Buffer)
        for i, part_number in enumerate(count(part_number_start)):
            if isinstance(file, Buffer):
                chunk = memoryview(file)[i*partsize:(i+1)*partsize]
                if not chunk:
                    break
            else:
                if async_:
                    chunk = bio_chunk_async_iter(file, partsize)
                else:
                    chunk = bio_chunk_iter(cast(SupportsRead, file), partsize)
                chunk = yield peek_iter(chunk)
                if not chunk:
                    break
                chunk = cast(Iterator[Buffer] | AsyncIterator[Buffer], chunk)
                if reporthook is not None:
                    chunk = wrap_iter(chunk, callnext=lambda b: reporthook(buffer_length(b)))
            part = yield Yield(oss_multipart_upload_part(
                url=url, 
                file=chunk, # type: ignore
                upload_id=upload_id, 
                part_number=part_number, 
                token=token, 
                async_=async_, # type: ignore
                **request_kwargs, 
            ))
            if end_with_reporthook:
                reporthook(buffer_length(chunk)) # type: ignore
            if part["Size"] < partsize:
                break
    return run_gen_step_iter(gen_step, async_)


@overload
def oss_upload_init(
    file: Buffer | str | PathLike | URL | SupportsGeturl | SupportsRead, 
    pid: int | str = 0, 
    filename: str = "", 
    filesha1: str = "", 
    filesize: int = -1, 
    user_id: int | str = "", 
    user_key: str = "", 
    endpoint: str = "http://oss-cn-shenzhen.aliyuncs.com", 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> dict:
    ...
@overload
def oss_upload_init(
    file: Buffer | str | PathLike | URL | SupportsGeturl | SupportsRead, 
    pid: int | str = 0, 
    filename: str = "", 
    filesha1: str = "", 
    filesize: int = -1, 
    user_id: int | str = "", 
    user_key: str = "", 
    endpoint: str = "http://oss-cn-shenzhen.aliyuncs.com", 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, dict]:
    ...
def oss_upload_init(
    file: Buffer | str | PathLike | URL | SupportsGeturl | SupportsRead, 
    pid: int | str = 0, 
    filename: str = "", 
    filesha1: str = "", 
    filesize: int = -1, 
    user_id: int | str = "", 
    user_key: str = "", 
    endpoint: str = "http://oss-cn-shenzhen.aliyuncs.com", 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> dict | Coroutine[Any, Any, dict]:
    """å‡†å¤‡åˆ†å—ä¸Šä¼ ï¼Œè·å–å¿…è¦ä¿¡æ¯

    .. note::
        å¦‚æœä½ å¹¶æ²¡æœ‰åŒæ—¶æä¾› user_id å’Œ user_keyï¼Œåˆ™è§†ä¸ºè°ƒç”¨ open æ¥å£ï¼Œéœ€è¦æºå¸¦ "authorization" è¯·æ±‚å¤´

    :param file: å¾…ä¸Šä¼ çš„æ–‡ä»¶æˆ–å…¶è·¯å¾„
    :param pid: ä¸Šä¼ æ–‡ä»¶åˆ°ç›®å½•çš„ id
    :param filename: æ–‡ä»¶åï¼Œè‹¥ä¸ºç©ºåˆ™è‡ªåŠ¨ç¡®å®š
    :param filesha1: æ–‡ä»¶çš„ sha1 æ‘˜è¦ï¼Œè‹¥ä¸ºç©ºåˆ™è‡ªåŠ¨è®¡ç®—
    :param filesize: æ–‡ä»¶å¤§å°ï¼Œè‹¥ä¸ºè´Ÿæ•°åˆ™è‡ªåŠ¨è®¡ç®—
    :param user_id: ç”¨æˆ· id
    :param user_key: ç”¨æˆ·çš„ key
    :param endpoint: ä¸Šä¼ ç›®çš„ç½‘å€
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: å¦‚æœç§’ä¼ æˆåŠŸï¼Œåˆ™è¿”å›å“åº”ä¿¡æ¯ï¼ˆæœ‰ "status" å­—æ®µï¼‰ï¼Œå¦åˆ™è¿”å›ä¸Šä¼ é…ç½®ä¿¡æ¯ï¼ˆå¯ç”¨äºæ–­ç‚¹ç»­ä¼ ï¼‰
    """
    use_open = not (user_id and user_key)
    def gen_step():
        nonlocal file, filename, filesha1, filesize
        upload_data: dict = {}
        if not use_open:
            upload_data["user_id"] = user_id
            upload_data["user_key"] = user_key
        read_range: Callable
        try:
            file = getattr(file, "getbuffer")()
        except (AttributeError, TypeError):
            pass
        if isinstance(file, Buffer):
            data = file
            filesize = buffer_length(data)
            if filesize == 0:
                filesha1 = "DA39A3EE5E6B4B0D3255BFEF95601890AFD80709"
            elif not filesha1:
                filesha1 = sha1(data).hexdigest()
            def read_range(sign_check: str, /) -> bytes:
                start, end = map(int, sign_check.split("-"))
                return memoryview(data)[start:end+1].tobytes()
        elif isinstance(file, SupportsRead):
            if not filename:
                from os.path import basename
                filename = getattr(file, "name", "")
                filename = basename(filename)
            if not filesha1:
                if filesize == 0:
                    filesha1 = "DA39A3EE5E6B4B0D3255BFEF95601890AFD80709"
                else:
                    if async_:
                        filesize, filesha1_obj = yield file_digest_async(file, "sha1")
                    else:
                        filesize, filesha1_obj = file_digest(file, "sha1")
                    filesha1 = filesha1_obj.hexdigest()
            if filesize < 0:
                try:
                    fileno = getattr(file, "fileno")()
                    filesize = fstat(fileno).st_size
                except (AttributeError, TypeError, OSError):
                    for attr in ("length", "getlength", "__len__"):
                        if hasattr(file, attr):
                            length = getattr(file, attr)
                            if callable(length):
                                length = length()
                            if async_ and isawaitable(length):
                                length = yield length
                            filesize = length
                            break
                    else:
                        seek = getattr(file, "seek")
                        if async_:
                            filesize = yield ensure_async(seek, threaded=True)(0, 2)
                        else:
                            filesize = seek(0, 2)
            reader: Any = file
            if async_:
                async def read_range(sign_check: str, /) -> bytes:
                    start, end = map(int, sign_check.split("-"))
                    await ensure_async(reader.seek, threaded=True)(start)
                    return await ensure_async(reader.read, threaded=True)(end - start + 1)
            else:
                def read_range(sign_check: str, /) -> bytes:
                    start, end = map(int, sign_check.split("-"))
                    reader.seek(start)
                    return reader.read(end - start + 1)
        else:
            path = file
            is_url = False
            if isinstance(path, str):
                is_url = path.startswith(("http://", "https://"))
            elif isinstance(path, (URL, SupportsGeturl)):
                is_url = True
                if isinstance(path, URL):
                    path = str(path)
                else:
                    path = path.geturl()
            else:
                path = fsdecode(path)
            path = cast(str, path)
            if not filesha1:
                if filesize == 0:
                    filesha1 = "DA39A3EE5E6B4B0D3255BFEF95601890AFD80709"
                else:
                    if is_url:
                        if async_:
                            from httpfile import AsyncHTTPFileReader
                            async def process():
                                reader = await AsyncHTTPFileReader.new(path, headers=_HEADERS)
                                async with reader:
                                    return await file_digest_async(reader, "sha1")
                            filesize, filesha1_obj = yield process()
                        else:
                            from httpfile import HTTPFileReader
                            with HTTPFileReader(path, headers=_HEADERS) as reader:
                                filesize, filesha1_obj = file_digest(reader, "sha1")
                    else:
                        def make_hash(path, /):
                            with open(path, "rb") as file:
                                return file_digest(file, "sha1")
                        if async_:
                            filesize, filesha1_obj = yield to_thread(make_hash, path)
                        else:
                            filesize, filesha1_obj = make_hash(path)
                filesha1 = filesha1_obj.hexdigest()
            if filesize < 0:
                if is_url:
                    from http_client_request import request
                    if async_:
                        response = yield to_thread(request, path)
                    else:
                        response = request(path)
                    if not filename:
                        filename = get_filename(response)
                    with response:
                        length = get_total_length(response)
                        if length is None:
                            raise ValueError(f"can't get file size: {path!r}")
                        filesize = length
                else:
                    filesize = stat(path).st_size
            if not filename:
                if is_url:
                    from posixpath import basename
                    from urllib.parse import unquote
                    filename = basename(unquote(urlsplit(path).path))
                else:
                    from os.path import basename
                    filename = basename(path)
            def read_range(sign_check: str, /) -> bytes:
                if is_url:
                    from http_client_request import request
                    headers: dict = {**_HEADERS, "range": "bytes="+sign_check}
                    with request(path, headers=headers) as response:
                        return response.read()
                else:
                    start, end = map(int, sign_check.split("-"))
                    with open(path, "rb") as reader:
                        reader.seek(start)
                        return reader.read(end - start + 1)
        if not filename:
            filename = str(uuid4())
        filesha1 = filesha1.upper()
        if isinstance(pid, str) and pid.startswith("U_"):
            target = pid
        else:
            target = f"U_1_{pid or 0}"
        upload_data.update(filename=filename, filesha1=filesha1, filesize=filesize, target=target)
        if use_open:
            payload = {
                "fileid": filesha1, 
                "file_name": filename, 
                "file_size": filesize, 
                "target": target, 
            }
            do_upload_init = upload_init_open
        else:
            payload = {
                "fileid": filesha1, 
                "filename": filename, 
                "filesize": filesize, 
                "target": target, 
                "userid": user_id, 
                "userkey": user_key, 
            }
            do_upload_init = upload_init
        resp = data = yield do_upload_init(payload, async_=async_, **request_kwargs)
        if use_open:
            if not resp["state"]:
                return resp
            data = resp["data"]
        status = data["status"]
        if status == 7:
            sign_key: str = data["sign_key"]
            sign_check: str = data["sign_check"]
            payload["sign_key"] = sign_key
            if async_:
                read_range = ensure_async(read_range, threaded=True)
            data = yield read_range(sign_check)
            payload["sign_val"] = sha1(data).hexdigest().upper()
            resp = data = yield do_upload_init(payload, async_=async_, **request_kwargs)
            if use_open:
                if not resp["state"]:
                    return resp
                data = resp["data"]
            status = data["status"]
        if status == 2:
            if use_open:
                pickcode = data["pick_code"]
            else:
                pickcode = resp["pickcode"]
            upload_data["pickcode"] = pickcode
            upload_data["id"] = pickcode_to_id(pickcode)
            resp["state"] = True
            resp["reuse"] = True
        elif status == 1:
            resp["state"] = True
            resp["reuse"] = False
            upload_data["callback"] = data["callback"]
            upload_data["bucket"] = data["bucket"]
            upload_data["object"] = data["object"]
            upload_data["url"] = upload_endpoint_url(data["object"], data["bucket"], endpoint=endpoint)
            resp["data"] = upload_data
        else:
            resp["state"] = False
            resp["reuse"] = False
        if use_open:
            data.update(upload_data)
        else:
            resp["data"] = upload_data
        return resp
    return run_gen_step(gen_step, async_)


@overload
def oss_upload(
    file: Buffer | SupportsRead | Iterable[Buffer], 
    callback: dict, 
    url: str = "", 
    token: None | dict = None, 
    reporthook: None | Callable[[int], Any] = None, 
    endpoint: str = "http://oss-cn-shenzhen.aliyuncs.com", 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> dict:
    ...
@overload
def oss_upload(
    file: Buffer | SupportsRead | Iterable[Buffer] | AsyncIterable[Buffer], 
    callback: dict, 
    url: str = "", 
    token: None | dict = None, 
    reporthook: None | Callable[[int], Any] = None, 
    endpoint: str = "http://oss-cn-shenzhen.aliyuncs.com", 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, dict]:
    ...
def oss_upload(
    file: Buffer | SupportsRead | Iterable[Buffer] | AsyncIterable[Buffer], 
    callback: dict, 
    url: str = "", 
    token: None | dict = None, 
    reporthook: None | Callable[[int], Any] = None, 
    endpoint: str = "http://oss-cn-shenzhen.aliyuncs.com", 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> dict | Coroutine[Any, Any, dict]:
    """ä¸€æ¬¡æ€§ä¸Šä¼ æ–‡ä»¶åˆ°é˜¿é‡Œäº‘ OSS

    :param file: æ–‡ä»¶æ•°æ®
    :param callback: å›è°ƒæ•°æ®
    :param url: HTTP è¯·æ±‚é“¾æ¥
    :param token: ä¸Šä¼ ç”¨åˆ°çš„ä»¤ç‰Œä¿¡æ¯ï¼ˆå­—å…¸ï¼‰
    :param reporthook: å›è°ƒå‡½æ•°ï¼Œå¯ä»¥ç”¨æ¥ç»Ÿè®¡å·²ä¸Šä¼ çš„æ•°æ®é‡æˆ–è€…å±•ç¤ºè¿›åº¦æ¡
    :param endpoint: ä¸Šä¼ ç›®çš„ç½‘å€ï¼ˆå¦‚æœæœªæä¾› url çš„è¯ï¼‰
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: æ¥å£å“åº”
    """
    if reporthook is not None:
        if isinstance(file, Buffer):
            if async_:
                file = bytes_to_chunk_async_iter(file)
            else:
                file = bytes_to_chunk_iter(file)
        elif isinstance(file, SupportsRead):
            if async_:
                file = bio_chunk_async_iter(file)
            else:
                file = bio_chunk_iter(file)
        file = wrap_iter(file, callnext=lambda b: reporthook(buffer_length(b)))
    def gen_step():
        nonlocal url
        if not url:
            resp = yield upload_resume(callback, async_=async_, **request_kwargs)
            if resp["status"] != 1:
                resp["state"] = False
                return resp
            url = upload_endpoint_url(resp["object"], resp["bucket"], endpoint=endpoint)
        elif not url.startswith(("http://", "https://")):
            url = upload_endpoint_url(url, endpoint=endpoint)
        request_kwargs.update(
            method="PUT", 
            data=file, 
            headers=dict_update(
            dict(request_kwargs.get("headers") or ()), 
                {
                    "x-oss-callback": to_base64(callback["callback"]), 
                    "x-oss-callback-var": to_base64(callback["callback_var"]), 
                }, 
            ), 
        )
        return oss_upload_request(
            url=url, 
            token=token, 
            async_=async_, 
            **request_kwargs, 
        )
    return run_gen_step(gen_step, async_)


@overload
def oss_multipart_upload(
    file: Buffer | SupportsRead | Iterable[Buffer], 
    callback: dict, 
    url: str = "", 
    upload_id: None | str = None, 
    partsize: int = 1024 * 1024 * 10, 
    parts: None | list[dict] = None, 
    token: None | dict = None, 
    reporthook: None | Callable[[int], Any] = None, 
    endpoint: str = "http://oss-cn-shenzhen.aliyuncs.com", 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> dict:
    ...
@overload
def oss_multipart_upload(
    file: Buffer | SupportsRead | Iterable[Buffer] | AsyncIterable[Buffer], 
    callback: dict, 
    url: str = "", 
    upload_id: None | str = None, 
    partsize: int = 1024 * 1024 * 10, 
    parts: None | list[dict] = None, 
    token: None | dict = None, 
    reporthook: None | Callable[[int], Any] = None, 
    endpoint: str = "http://oss-cn-shenzhen.aliyuncs.com", 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, dict]:
    ...
def oss_multipart_upload(
    file: Buffer | SupportsRead | Iterable[Buffer] | AsyncIterable[Buffer], 
    callback: dict, 
    url: str = "", 
    upload_id: None | str = None, 
    partsize: int = 1024 * 1024 * 10, 
    parts: None | list[dict] = None, 
    token: None | dict = None, 
    reporthook: None | Callable[[int], Any] = None, 
    endpoint: str = "http://oss-cn-shenzhen.aliyuncs.com", 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> dict | Coroutine[Any, Any, dict]:
    """åˆ†å—ä¸Šä¼ æ–‡ä»¶åˆ°é˜¿é‡Œäº‘ OSS

    .. attention::
        å¦‚æœéœ€è¦è·³è¿‡ä¸€å®šçš„æ•°æ®ï¼Œè¯·æå‰å¤„ç†å¥½ï¼Œè¿™ä¸ªä¸ç®¡æ•°æ®æ˜¯å¦è¢«é‡å¤ä¸Šä¼     

    :param file: æ–‡ä»¶æ•°æ®
    :param callback: å›è°ƒæ•°æ®
    :param url: HTTP è¯·æ±‚é“¾æ¥
    :param upload_id: ä¸Šä¼ ä»»åŠ¡ id
    :param partsize: åˆ†å—å¤§å°
    :pamra parts: å·²å®Œæˆçš„åˆ†å—ä¿¡æ¯åˆ—è¡¨
    :param token: ä¸Šä¼ ç”¨åˆ°çš„ä»¤ç‰Œä¿¡æ¯ï¼ˆå­—å…¸ï¼‰
    :param reporthook: å›è°ƒå‡½æ•°ï¼Œå¯ä»¥ç”¨æ¥ç»Ÿè®¡å·²ä¸Šä¼ çš„æ•°æ®é‡æˆ–è€…å±•ç¤ºè¿›åº¦æ¡
    :param endpoint: ä¸Šä¼ ç›®çš„ç½‘å€ï¼ˆå¦‚æœæœªæä¾› url çš„è¯ï¼‰
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: æ¥å£å“åº”
    """
    if partsize <= 0:
        partsize = 1024 * 1024 * 10
    def gen_step():
        nonlocal url, upload_id, parts
        if not url or upload_id:
            resp = yield upload_resume(callback, async_=async_, **request_kwargs)
            if resp["status"] != 1:
                resp["state"] = False
                return resp
            if not url or not url.startswith(("http://", "https://")):
                url = upload_endpoint_url(resp["object"], resp["bucket"], endpoint=endpoint)
        if not url.startswith(("http://", "https://")):
            url = upload_endpoint_url(url, endpoint=endpoint)
        if not upload_id:
            upload_id = yield oss_multipart_upload_init(
                url=url, 
                token=token, 
                async_=async_, 
                **request_kwargs, 
            )
            upload_id = cast(str, upload_id)
            if parts is None:
                parts = []
            else:
                assert not parts
        elif parts is None:
            parts = []
            yield foreach(
                parts.append, 
                oss_multipart_part_iter(
                    url=url, 
                    upload_id=upload_id, 
                    token=token, 
                    async_=async_, 
                    **request_kwargs, 
                ), 
            )
        yield foreach(
            parts.append, 
            oss_multipart_upload_part_iter(
                url=url, 
                file=file, # type: ignore
                upload_id=upload_id, 
                partsize=partsize, 
                part_number_start=len(parts)+1, 
                token=token, 
                reporthook=reporthook, 
                async_=async_, # type: ignore
                **request_kwargs, 
            ), 
        )
        return (yield oss_multipart_upload_complete(
            url=url, 
            callback=callback, 
            upload_id=upload_id, 
            parts=parts, 
            token=token, 
            async_=async_, 
            **request_kwargs, 
        ))
    return run_gen_step(gen_step, async_)


@overload
def upload(
    file: Buffer | str | PathLike | URL | SupportsGeturl | SupportsRead, 
    pid: int | str = 0, 
    filename: str = "", 
    filesha1: str = "", 
    filesize: int = -1, 
    user_id: int | str = "", 
    user_key: str = "", 
    partsize: int = 0, 
    callback: None | dict = None, 
    upload_id: str = "", 
    endpoint: str = "http://oss-cn-shenzhen.aliyuncs.com", 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> dict:
    ...
@overload
def upload(
    file: Buffer | str | PathLike | URL | SupportsGeturl | SupportsRead, 
    pid: int | str = 0, 
    filename: str = "", 
    filesha1: str = "", 
    filesize: int = -1, 
    user_id: int | str = "", 
    user_key: str = "", 
    partsize: int = 0, 
    callback: None | dict = None, 
    upload_id: str = "", 
    endpoint: str = "http://oss-cn-shenzhen.aliyuncs.com", 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, dict]:
    ...
def upload(
    file: Buffer | str | PathLike | URL | SupportsGeturl | SupportsRead, 
    pid: int | str = 0, 
    filename: str = "", 
    filesha1: str = "", 
    filesize: int = -1, 
    user_id: int | str = "", 
    user_key: str = "", 
    partsize: int = 0, 
    callback: None | dict = None, 
    upload_id: str = "", 
    endpoint: str = "http://oss-cn-shenzhen.aliyuncs.com", 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> dict | Coroutine[Any, Any, dict]:
    """ä¸Šä¼ æ–‡ä»¶

    .. note::
        å¦‚æœæä¾›äº† ``callback``ï¼Œåˆ™å¼ºåˆ¶ä¸ºåˆ†å—ä¸Šä¼ ã€‚
        æ­¤æ—¶ï¼Œæœ€å¥½æä¾›ä¸€ä¸‹ ``upload_id``ï¼Œå¦åˆ™å°±æ˜¯ä»å¤´å¼€å§‹ã€‚
        æ­¤æ—¶å¯ä»¥çœç•¥ ``pid``ã€``filename``ã€``filesha1``ã€``filesize``ã€``user_id``ã€``user_key``ã€``partsize``

    .. caution::
        ``partsize > 0`` æ—¶ï¼Œä¸è¦æŠŠ ``partsize`` è®¾ç½®å¾—å¤ªå°ï¼Œèµ·ç å¾— 10 MB (10485760) ä»¥ä¸Š

    :param file: å¾…ä¸Šä¼ çš„æ–‡ä»¶æˆ–å…¶è·¯å¾„
    :param pid: ä¸Šä¼ æ–‡ä»¶åˆ°ç›®å½•çš„ id
    :param filename: æ–‡ä»¶åï¼Œè‹¥ä¸ºç©ºåˆ™è‡ªåŠ¨ç¡®å®š
    :param filesha1: æ–‡ä»¶çš„ sha1 æ‘˜è¦ï¼Œè‹¥ä¸ºç©ºåˆ™è‡ªåŠ¨è®¡ç®—
    :param filesize: æ–‡ä»¶å¤§å°ï¼Œè‹¥ä¸ºè´Ÿæ•°åˆ™è‡ªåŠ¨è®¡ç®—
    :param user_id: ç”¨æˆ· id
    :param user_key: ç”¨æˆ·çš„ key
    :param partsize: åˆ†å—å¤§å°ï¼ˆå¦‚æœä¸º 0ï¼Œåˆ™ä¸æ˜¯åˆ†å—ä¸Šä¼ ï¼›å¦‚æœ <0ï¼Œåˆ™è‡ªåŠ¨ç¡®å®šï¼‰
    :param callback: å›è°ƒæ•°æ®
    :param upload_id: ä¸Šä¼ ä»»åŠ¡ id
    :param endpoint: ä¸Šä¼ ç›®çš„ç½‘å€
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: æ¥å£å“åº”
    """
    def gen_step():
        nonlocal file, partsize, callback
        parts: None | list[dict] = None
        skip_size = 0
        if callback:
            resp = yield upload_resume(callback, async_=async_, **request_kwargs)
            if not resp["state"]:
                return resp
            url = upload_endpoint_url(resp["object"], resp["bucket"], endpoint=endpoint)
            if upload_id:
                parts = []
                yield foreach(
                    parts.append, 
                    oss_multipart_part_iter(
                        url=url, 
                        upload_id=upload_id, 
                        async_=async_, 
                        **request_kwargs, 
                    ), 
                )
                skip_size = sum(p["Size"] for p in parts)
        else:
            resp = yield oss_upload_init(
                file=file, 
                pid=pid, 
                filename=filename, 
                filesha1=filesha1, 
                filesize=filesize, 
                user_id=user_id, 
                user_key=user_key, 
                endpoint=endpoint, 
                async_=async_, 
                **request_kwargs, 
            )
            if not resp["state"] or resp["reuse"]:
                return resp
            upload_data = resp["data"]
            url = upload_data["url"]
            callback = upload_data["callback"]
            if partsize:
                if partsize < 0:
                    partsize = determine_partsize(upload_data["filesize"])
            else:
                if isinstance(file, SupportsRead):
                    seek = getattr(file, "seek")
                    if async_:
                        yield ensure_async(seek, threaded=True)(0)
                    else:
                        seek(0)
                elif not isinstance(file, Buffer):
                    path = file
                    is_url = False
                    if isinstance(path, str):
                        is_url = path.startswith(("http://", "https://"))
                    elif isinstance(path, (URL, SupportsGeturl)):
                        is_url = True
                        if isinstance(path, URL):
                            path = str(path)
                        else:
                            path = path.geturl()
                    else:
                        path = fsdecode(path)
                    path = cast(str, path)
                    if is_url:
                        if async_:
                            from httpfile import AsyncHTTPFileReader
                            async def process():
                                return await AsyncHTTPFileReader.new(cast(str, path), headers=_HEADERS)
                            file = yield process()
                        else:
                            from httpfile import HTTPFileReader
                            file = HTTPFileReader(path, headers=_HEADERS)
                    else:
                        file = open(path, "rb")
                file = cast(Buffer | SupportsRead, file)
                return oss_upload(
                    file, 
                    callback=callback, 
                    url=url, 
                    async_=async_, 
                    **request_kwargs, 
                )
        if isinstance(file, SupportsRead):
            seek = getattr(file, "seek")
            if async_:
                yield ensure_async(seek, threaded=True)(skip_size)
            else:
                seek(skip_size)
        elif not isinstance(file, Buffer):
            path = file
            is_url = False
            if isinstance(path, str):
                is_url = path.startswith(("http://", "https://"))
            elif isinstance(path, (URL, SupportsGeturl)):
                is_url = True
                if isinstance(path, URL):
                    path = str(path)
                else:
                    path = path.geturl()
            else:
                path = fsdecode(path)
            path = cast(str, path)
            if is_url:
                if async_:
                    from httpfile import AsyncHTTPFileReader
                    async def process():
                        return await AsyncHTTPFileReader.new(path, headers=_HEADERS, start=skip_size)
                    file = yield process()
                else:
                    from httpfile import HTTPFileReader
                    file = HTTPFileReader(path, headers=_HEADERS, start=skip_size)
            else:
                file = open(path, "rb")
                if skip_size:
                    file.seek(skip_size)
        file = cast(Buffer | SupportsRead, file)
        return oss_multipart_upload(
            file=file, 
            callback=callback, 
            url=url, 
            upload_id=upload_id, 
            partsize=partsize, 
            parts=parts, 
            async_=async_, 
            **request_kwargs, 
        )
    return run_gen_step(gen_step, async_)

# TODO: å…ˆç”¨ç€ï¼Œå¦‚æœå‘ç°åˆ†å—ä¸Šä¼ ç”¨æ–­ç‚¹ç»­ä¼ ï¼Œè€Œæœ‰äº›å·²ç»ä¸Šä¼ çš„åˆ†å—å› ä¸ºä¸­é€”å¤±è´¥ï¼Œå¯¼è‡´ä¸Šä¼ çš„å—å¤ªå°ï¼Œå¯¼è‡´æœ€ååˆå¹¶æ—¶æŠ¥é”™ï¼Œé‚£ä¹ˆä»¥åå°±è¦è·³è¿‡è¿™äº›åˆ†å—ï¼ˆè¿™æ˜¯ partsize ä¼šæœ‰ä¸€ä¸ªé™åˆ¶çš„æœ€å°å€¼ï¼Œä¾‹å¦‚ 64 KBï¼Œå°äºæ­¤å€¼ï¼Œåˆ™åˆ†å—ä¼šè¢«å¿½ç•¥ï¼‰
